{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overhead of Functions and Coroutines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 loops, best of 3: 75.9 ns per loop\n"
     ]
    }
   ],
   "source": [
    "def test(a):\n",
    "    return a\n",
    "\n",
    "%timeit test(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get 10M function calls per second (a few hundred CPU clock cycles). This is about 100 times slower than what can be achieved in low level languages.\n",
    "CPython does use the C stack for function calls and spins up a new interpreter loop for each call. However, it uses a custom frame object for the actual Python content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this for comparison with generators (reading the numbers from a precomputed list should be faster...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 8.11 µs per loop\n"
     ]
    }
   ],
   "source": [
    "numbers = list(range(1000))\n",
    "\n",
    "%timeit sum(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 108 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def generator_func():\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i += 1\n",
    "        yield i\n",
    "\n",
    "%timeit sum(generator_func())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while this is ten times slower, we can still manage about 10M iterations per second (similar to the number of function calls we can manage).\n",
    "Under the hood CPython keeps the frame object and reuses it when entering the function again, but a new C stack frame is pushed each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about nesting generators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 177 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def generator_wrapper(inner_iterator):\n",
    "    yield from inner_iterator\n",
    "\n",
    "%timeit sum(generator_wrapper(generator_wrapper(generator_func())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while nesting added some overhead, the effect is not dramatic (we still manage about five million iterations per second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain function calls in a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 184 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def test_func(i):\n",
    "    return i + 1;\n",
    "\n",
    "def generator_calling_func():\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i = test_func(i)\n",
    "        yield i\n",
    "        \n",
    "%timeit sum(generator_calling_func())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asyncio overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of switching to another thread is hard to estimate, but a rough estimate might be $30 \\mu s$. If entering a generator takes $100ns$ then this should be enough for 300 such enterings in the same amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 468 µs per loop\n"
     ]
    }
   ],
   "source": [
    "async def counter():\n",
    "    sum = 0\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i = await get_next(i)\n",
    "        sum += i\n",
    "    return sum\n",
    "\n",
    "async def get_next(i):\n",
    "    return i + 1\n",
    "    \n",
    "%timeit loop.run_until_complete(counter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each iteration takes about $500ns$, and the event loop could perform about 2 million iterations per second."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
