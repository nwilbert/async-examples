{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overhead of using a generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(a):\n",
    "    return a\n",
    "\n",
    "%timeit test(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get 1E7 function calls per second (a few thousand CPU clock cycles). This is about 100 times slower than what can be achieved in low level languages.\n",
    "CPython does use the C stack for function calls and spins up a new interpreter loop for each call. However, it uses a custom frame object for the actual Python content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers = list(range(1000))\n",
    "\n",
    "%timeit sum(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 106 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def generator_func():\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i += 1\n",
    "        yield i\n",
    "\n",
    "%timeit sum(generator_func())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while this is ten times slower, we can still manage about 1E7 iterations per second (similar to the number of function calls we can manage).\n",
    "Under the hood CPython keeps the frame object and reuses it when entering the function again, but a new C stack frame is pushed each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about nesting generators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 199 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def generator_func():\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i += 1\n",
    "        yield i\n",
    "        \n",
    "def generator_wrapper(inner_iterator):\n",
    "    yield from inner_iterator\n",
    "\n",
    "%timeit sum(generator_wrapper(generator_wrapper(generator_func())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while nesting added some overhead, the effect is not dramatic (we still manage about five million iterations per second)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain function calls in a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 194 µs per loop\n"
     ]
    }
   ],
   "source": [
    "def test_func(i):\n",
    "    return i + 1;\n",
    "\n",
    "def generator_calling_func():\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i = test_func(i)\n",
    "        yield i\n",
    "        \n",
    "%timeit sum(generator_calling_func())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asyncio overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of switching to another thread can be estimated at $> 30 \\mu s$. If the estimate entering a generator $100ns$ the this is enough for 300 such entering, so one would assume that the async/await approach has at least 10 times less overhead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 454 µs per loop\n"
     ]
    }
   ],
   "source": [
    "async def counter():\n",
    "    sum = 0\n",
    "    i = 0\n",
    "    while i < 1000:\n",
    "        i = await get_next(i)\n",
    "        sum += i\n",
    "    return sum\n",
    "\n",
    "async def get_next(i):\n",
    "    return i + 1\n",
    "    \n",
    "%timeit loop.run_until_complete(counter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each iteration takes about $400ns$, and the event loop could perform about 2 million iterations per second."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
